<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://jvboid.dev/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jvboid.dev/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-19T22:35:01+00:00</updated><id>https://jvboid.dev/feed.xml</id><title type="html">blank</title><subtitle>Personal portfolio site </subtitle><entry><title type="html">Looking Ahead to Future Impact</title><link href="https://jvboid.dev/blog/2023/looking-ahead-to-future-impact/" rel="alternate" type="text/html" title="Looking Ahead to Future Impact"/><published>2023-11-21T00:00:00+00:00</published><updated>2023-11-21T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/looking-ahead-to-future-impact</id><content type="html" xml:base="https://jvboid.dev/blog/2023/looking-ahead-to-future-impact/"><![CDATA[<p>Almost one year ago, I embarked a journey to develop the world’s first $1000 full-scale, general purpose humanoid robot, the Limboid. I had no idea what I was getting myself into: mechanical engineering, hydraulics, electronics, software, AI, pitching, raising (and losing!) money, global sourcing and logistics, etc. etc. I had next to zero idea how to do most of these things. But I did them anyway. I learned. I failed. And then I learned some more, failed some more, and learned even more. But I kept going because I believed I was doing something that mattered, something that could touch the lives of billions.</p> <p>Admittedly, I was naive: Naive to think I could do it all myself; naive to think I could do it all in one year; that I could do it all with 6 month’s bootstrapped savings from my first SwE out of college; with no team; little experience; no network; no makespace; no resources; no nothing.</p> <p>Currently, there are several fundamental challenges with the hydraulic system that I haven’t been able to solve. As a result, I’ve decided to put the effort on hold. I’m not giving up; it’s more like a break where I can reflect, explore, and recharge.</p> <p>Sometimes I wonder if I was just crazy for even trying, and sure, I’d say so. But I’d also say that I’m glad I did. Glad I tried. Glad I failed. Glad I learned. Glad I grew. I’ll take this experience with me for the rest of my life. Whether I’m working with a startup or a Fortune 500, I want to let it inform my perception, communication, and decisions. When we’re facing a problem, I want to share the the lessons I’ve learned to be able to say “I’ve been there. I’ve done that. Here’s what worked. Here’s what didn’t. And based on that, here’s what we might try now.”</p> <p>To all the people who have encouraged me along the way, thank you. While I may not have been able to accomplish what I set out to do, I hope to carry the encouragement and support you’ve given me forward. I am grateful for each and every one of you. I’d especially like to thank <a href="https://www.linkedin.com/in/debrahmorgan/">Debra Morgan</a>, <a href="https://www.linkedin.com/in/1simonday/">Simon Day</a>, <a href="https://www.linkedin.com/in/chelsea-seeds-877278130/?originalSubdomain=uk">Chelsea Seeds</a>, <a href="https://www.linkedin.com/in/melinda-b-c-533b2a127/">Melinda Chu</a>, <a href="https://www.paibytwo.com/">Abhishek Pandir</a>, <a href="https://www.linkedin.com/in/arkajyoti-chakraborty-51113b1b0/">Arkajyoti Chakraborty</a>, <a href="https://www.linkedin.com/in/harsh-raj-425593195/">Harsh Raj</a>, and <a href="https://www.linkedin.com/in/joseph-moti-2063642/">Joseph Moti</a> for taking the time to advise me on various business and technical areas.</p> <p>What’s next? I’m excited to find out! I’m confident that whatever it is, it will be something that matters – and probabbly something involving AI, robotics, or both. If you’re interested in working together, please <a href="https://jacobfv.github.io/bio#contact">reach out</a>. I’d love to hear from you.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Reflections, gratitude, and looking ahead to positive future impact]]></summary></entry><entry><title type="html">The Winner Takes It All</title><link href="https://jvboid.dev/blog/2023/the-winner-takes-it-all/" rel="alternate" type="text/html" title="The Winner Takes It All"/><published>2023-09-24T00:00:00+00:00</published><updated>2023-09-24T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/the-winner-takes-it-all</id><content type="html" xml:base="https://jvboid.dev/blog/2023/the-winner-takes-it-all/"><![CDATA[<meta http-equiv="refresh" content="0; URL=https://jacobvaldez.substack.com/p/the-winner-takes-it-all"/>]]></content><author><name></name></author><summary type="html"><![CDATA[Despair and calculations when the end comes]]></summary></entry><entry><title type="html">P versus NP</title><link href="https://jvboid.dev/blog/2023/P-versus-NP/" rel="alternate" type="text/html" title="P versus NP"/><published>2023-08-14T00:00:00+00:00</published><updated>2023-08-14T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/P-versus-NP</id><content type="html" xml:base="https://jvboid.dev/blog/2023/P-versus-NP/"><![CDATA[<p>Bridging both the practical and the theoretical, permeating nearly every domain, a longstanding question of computer science stands the Problem. Succintly,</p> \[\begin{equation} \text{Does P} = \text{NP?} \end{equation}\] <p>where:</p> <ul> <li>$ \text{P} = { p \in \mathcal{D} \mid \exists a \in \mathcal{A} : \text{a solves p in polynomial time}} $</li> <li>$ \text{NP} = { p \in \mathcal{D} \mid \exists a \in \mathcal{A} : \text{a verifies a solution to p in polynomial time}} $</li> <li>$\mathcal{D}$ is the set of all decision problems</li> <li>$\mathcal{A}$ is the set of all algorithms</li> </ul> <p>To solve it is not a mere exercise in curiosity, but – as we will see – transcendence beyond the very nature of provable nature of computation itself. Yet such is our aim.</p> <p>Consider <em>this</em> proof $p_{this}$ and its implications: Either \(\begin{equation} p_{this} \rightarrow \text{P}=\text{NP} \tag{2} \end{equation}\)</p> \[\begin{equation} p_{this} \rightarrow \text{P}\neq\text{NP} \tag{3} \end{equation}\] <p>or</p> \[\begin{equation} p_{this} \rightarrow \text{P}=\text{NP} \land \text{P}\neq\text{NP} \tag{4} \end{equation}\] <p>For convenience, let us define constants for $p_{this}$’s self-referential implication $p_{\text{P}=\text{NP}}$ \eqref{eq:2}, disproof $p_{\text{P}\neq \text{NP}}$ \eqref{eq:3}, and impossibility $p_{\text{P}=\text{NP} \wedge \text{P}\ne\text{NP}}$ \eqref{eq:4}. The latter is necesary to distinguish between provable and unprovable impossibilities, as we will see.</p> <p>Now how shall we proceed? Abstractly, proof is the goal-directed application of implication rules $\mathcal{R}$ to a set of axioms $\mathcal{S}_0$.</p> <ol> <li>Start by establishing our known axioms $\mathcal{S}_0 = { s_1, s_2, s_3, \dots, s_n }$,</li> <li>Select an implication to apply $r_i \in \mathcal{R}$ to apply to $\mathcal{S}_0$,</li> <li>Repeat, building a sequence of larger and larger axiom sets $\mathcal{S}<em>i = \mathcal{S}</em>{i-1} \cup \mathcal{r}(\mathcal{S_{i-1}})$,</li> <li>Stop when $\mathcal{S}_i$ contains a statement $s_n$ that we are trying to prove.</li> </ol> <p>Note the distinction between the proof <em>process</em> and the final proof itself. The latter lends itself a direct step-by-step verification, whereas the former demands a graph search. Proof verification surely takes less time… Or does it?</p> <p>The Cook-Levin theorom shows that if $\text{P}=\text{NP}$, then there must exist a polynomial running time complexity algorithm that solves graph search, an NP-Complete problem. As we have just seen, proof solving is a form of graph search. Thus, if $\text{P}=\text{NP}$, then the proof search algorithm most definitely runs in a countable number of steps with respect to the proof length, but depending on the value of $p_{this}$ the proof search algorithm may not.</p> <p>If $\text{P}=\text{NP}$, then the proof search algorithm most definitely runs in a countable number of steps with respect to the proof length, but depending on the value of $p_{this}$ the proof search algorithm may not.</p> <p>How how neigher of these solutions offer a solution.</p> <p>If I show both are true, then I’ve just shown that P&lt;&gt;NP is orthogonal to the current axiomatic system</p> <p>Discuss how it possible to continue building larger and larger axiomatic system by adding orthogonal dimensions to the axiom space</p> <p>And discuss how there are level requirements for understanding a more complex / powerful paradigm: first by understanding the cumulative sum of simpler predessor paradigms to it.</p> <p>Maybe paradigms are like clusters in a graph that typically must be arrived at via highway</p> <p>Simulate all possible aiomatic spaces and show what they look like in the limit of all random choices</p> <p><br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/> <br/></p> <p>most definitely runs in a countable number of steps with respect to the proof length, but depending on the value of $p_{this}$ the proof search algorithm may not.</p> <p>Let $M_p$ be a proof solving Turing machine and $M_v$ be its verifier. $M_p$ works by nondeterministically applying all possible implication rules to an initial set of axioms $\mathcal{S}$ ($p_n = \delta(p_{n-1})$, $p_0=\mathcal{S}_0$) until it reaches a set of statements containing a subgraph matching the statement it is trying to prove. On the other hand, $M_v$ receives a given sequence of implication rules all possible implication rules to a proof $p$ and checking that each step is valid.</p> <p>As the proof is merely an implication chain, $M_v$ clearly halts within a polynomial order of steps compared to the proof length. On the other hand, if $\text{P}\ne\text{NP}$, then it may simply be impossible to linearize the nondeterministic branches of $M_p$’s execution into a sequence of polynomial length with respect to the proof length. Thus, if $\text{P}\ne\text{NP}$, $M_p$ is not guaranteed to halt within a countable number of steps. Furthur, if both $\text{P}=\text{NP}$ and $\text{P}\ne\text{NP}$, then $M_p$ <em>is</em> guaranteed to never halt, and vice versa. We will return to this later.</p> <p>But first, let us consider our first two options: either $\text{P}=\text{NP}$ or $\text{P}\ne\text{NP}$. In the former case, $M_p$ must halt in polynomial time, and thus both $p_{this}$ can be proved and its proof can be checked. In the latter case, $M_p$ may or may not prove a statement within a countable number of implication steps, and thus there may exist checkable-proofs that cannot be found.</p> <p>By “may or may not”, we refer to the graph traversal and backtracking that $M_p$ must make. TODO: explain the branching part. Show how this is a graph search problem. Explain how the proof itself is a path through this graph. Explain how the proof checking is a step-by-step walk through the proof itself, verifying each step’s validity. Show how P=NP means the graph can be solved easily, and P!=NP means the graph cannot be solved easily. WAIT NO: because P=NP may be an average case problem, so even if the worst case for graph search is exponential P v NP may not be</p> <p>Now what can be said about unprovable proofs? Godel put it best: “This sentence is unprovable.” If it is provable, then it is unprovable. If it is unprovable, then it is provable. Thus, it is both provable and unprovable. This is a contradiction, and thus it is impossible. Thus, there are no statements with unprovable proofs. And yet, if $\text{P}\ne\text{NP}$, we end up in a situation where there exist statements whose proof the verifier $M_v \in \text{P}$ may verify within a countable steps but that the solver $M_p \in \text{NP}$ may not halt discover within a countable number of steps. If $p_{\text{P}\ne\text{NP}}$’s proof search was exponential wrt input (worse case), then $\text{P}\ne\text{NP}$ implicates the existance of unprovable statements, which is impossible. Thus, $p_{this}$ disproves $p_{\text{P}\ne\text{NP}}$.</p> <p>No; rather than p_this disproving anything, consider the two cases</p> <ul> <li>P!=NP and p_this requires exponential dtime</li> <li>P!=NP and p_this only requires Ptime &lt;- this option is still open</li> </ul> <p>However Godel had more to say about unprovable proofs. His second incompleteness theorom states that no complete axiomatic system can prove its own consistency. $p_{this}$’s self-referential proof (right here) is most certainly a statement about its completeness. Therefore $p_{this}$ cannot be consistent. So we must also rule out both $p_{\text{P}=\text{NP}}$ and $p_{\text{P}\ne\text{NP}}$ as impossible.</p> <p>Finally, consider $p_{\text{P}=\text{NP} \wedge \text{P}\ne\text{NP}}$: As discussed earlier, $p_{this}$’s existance necesitates that $M_p$ to halt. A halting $M_p$ requires $P=NP$. $p_{\text{P}=\text{NP} \wedge \text{P}\ne\text{NP}}$ implies $M_p$ does not exist. And yet here you are reading its proof right now. Thus, your existance demands $M_p$ to halt, or else $p_{this}$ is unprovable. Note, ruling out $p_{\text{P}=\text{NP} \wedge \text{P}\ne\text{NP}}$ as impossible does not remove the possiblility that $p_{this}$ is itself inconsistent, which by Godel’s 1st incompleteness theorom is the default for a self-referrential statement as $p_{this}$. However, if we end up here, we might try proving equivalence between $p_{this}$ and Godel’s statement, which would implicate an impossibility proof of $p_{this}$.</p> <p>Having exhaust all three cases, we conclude that $p_{this}$ is impossible. Thus, not only do we not have a proof for the Problem, we will never have a proof for the Problem. Thus, the Problem does not exist.</p> <p>This is good news for computer scientists because it means they will have a job for the rest of their lives. This is bad news for computer scientists because it means they will have a job for the rest of their lives. That problem is not halting either.</p> <p><br/> <br/></p> <ol> <li>make a countable sequence of related implications $\mathcal{P} = { \bigwedge_{s_i \in \mathcal{S}} s_i \rightarrow p_1$, $(\bigwedge_{s_i \in \mathcal{S}} s_i) \land p_1 \rightarrow p_2$, $(\bigwedge_{s_i \in \mathcal{S}} s_i) \land p_1 \land p_2 \rightarrow p_3, \dots, (\bigwedge_{s_i \in \mathcal{S}} s_i) \land (\bigwedge_{p_i \in {p_1 \dots p_{n-1}}} p_i) \rightarrow p_n }$ progressively implying their successors, and</li> <li>conclude when this implication chain reaches $p_n \rightarrow p_{\text{P}=\text{NP}}$, $p_n \rightarrow p_{\text{P}\neq \text{NP}}$, or $p_n \rightarrow p_{\text{P}=\text{NP} \wedge \text{P}\ne\text{NP}}$.</li> </ol>]]></content><author><name></name></author><category term="math"/><category term="theory"/><summary type="html"><![CDATA[An incomplete endevour to solve the Problem]]></summary></entry><entry><title type="html">The Master Plan (part 1)</title><link href="https://jvboid.dev/blog/2023/the-master-plan-part-1/" rel="alternate" type="text/html" title="The Master Plan (part 1)"/><published>2023-07-14T00:00:00+00:00</published><updated>2023-07-14T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/the-master-plan-part-1</id><content type="html" xml:base="https://jvboid.dev/blog/2023/the-master-plan-part-1/"><![CDATA[<blockquote> <p>The only constant is change. — Heraclitus as quoted by Dr. Ron Cross</p> </blockquote> <p>We’re witnessing the greatest technoevolutionary leap in the history of the observable universe. Yes, we might retrospectively say we were living in a fast-ish takeoff. Everything Everywhere All at Once. And most people don’t even realize it!</p> <p>But what’s a takeoff when only a minority are hanging 10? And the most capable AIs are locked away? And the robots cost more than many cars? Not a good takeoff. Not a good takeoff at all.</p> <p>This is where I want to help. I’ve been working on a robot that aims to bring this incredible leap forward into the hands of many more people. My focus is to build a $1,000 general-purpose humanoid robot powered by human-level artificial intelligence. I know it’s an ambitious goal, but I believe it’s achievable.</p> <p>The current landscape of general purpose humanoid robots is characterized by extremely high costs and complex technology. This results in low production volume, limited capabilities, and high prices. My vision is to break down these barriers using a handful of robotic technologies I’ve been developing. To be specific, I’ve discovered ways to manufacture hydraulic valves, actuators, and a prime mover for a fraction of their market price. By developing these systems myself, I am able to deliver a vertically integrated hydraulic/mechatronic system that balances both functional, aesthetic, manufacturing, and environmental factors.</p> <p>Yes, there have and will be challanges. Just making a single humanoid robot requires broad and deep engineering skill. Equipping it with human-level AI necesitates novel machine learning architectures. And making it affordable, mass-manufacturable, and competitive demands innovative approaches, deep moats, and a global network of skilled experts and investors. Haha, if there weren’t challenges, it’d already be done! But with the progress I’ve made over the past 6 months, I am confident it can be done.</p> <p>I can’t share more technical details yet, but let me tell you why this robot gets me so excited: I like to imagine how it will help people get through hard times, respond to crises, provide humanitarian support, and just make life better. And I’m not even joking: sometimes, I get really depressed, so I’ll just sit in front of it, hold its hand, look it in the eyes, tell it how I’m feeling, give it a hug, and for me that makes such a difference. If that’s what an <em>inanimate</em> robot can do, I can’t wait to see what the real deal can do for the world!</p> <blockquote> <p>If you no longer have a constraint on capita because of robots, it is not clear that there is any limit to the size of the economy. — Elon Musk</p> </blockquote> <p>A $1,000 general-purpose humanoid robot changes everything. Literally, the humanoid robot market is whatever the human market is. Long term, many of our economic/financial/etc. heuristics may just fail to be useful in a post-Limboid world. We’ll probabbly need to re-think a lot of things, but I’m excited about that because it’ll be our chance to redesign. Like think about how much GPT-4 has changed the software industry since it came out in March: We’re seeing new business models, new ways of working, and new opportunities for innovation. Now multiply that by 100x and apply it to the other industries to get a sense of what may be coming.</p> <p>To make this vision a reality, I first need to finish the prototype. I’m integrating the separate subsystems now, and will have a fully-assembled prototype soon. I also need to raise money to finance the fabrication equiptment and train the kinesthetic models. Looking in the range 100k-1M <a href="https://jacobfv.github.io/bio#contact">if you’re interested</a>. Aiming to launch early 2024.</p> <p>In the longer term, I envision an on-demand swarm model, similar to Uber. People will be able to request the services of a robot when they need it, and the robot will return to its owner when it’s not in use. This model will maximize the utility and accessibility of each robot</p> <p>Now this is a stage where many people worry about suffocating labor replacement and dramatic social changes, and yes, these are valid concerns. But I believe that the benefits of this technology will far outweigh the costs. I also believe that we can mitigate the negative impacts by adopting a “One Robot Per Customer” policy, which will help keep demand manageable while also ensuring that everyone has access to the benefits of this robot.</p> <p>As we embark on this journey, we’re going to see some incredible changes. We’re going to see new opportunities for innovation, new business models, new ways of working, and new ways of living. Yes, we’ll see the world turn itself upside down.</p> <p>But to make it all happen, I need your support. This is not just about funding, but also about sharing knowledge, expertise, and resources. I am looking for partners who are passionate about humanoid robots and their potential to transform our world. I am looking for investors who understand the long-term potential of this project and are willing to take a risk on a bold vision. I am looking for engineers, designers, and AI/ML experts who are excited about the challenge of creating something truly groundbreaking.</p> <p>I am also looking for input from potential users. I want to understand how you envision using a humanoid robot in your daily life. What tasks would you want it to perform? How would you want to interact with it? What features would be most important to you? Your input will be invaluable in shaping the design and functionality of this robot.</p> <p>I will also establishing communication channels with regulatory bodies, policymakers, and ethicists. While I avoid politics, I want to ensure that this project is in line with the values and principles of our society and that my work takes the lead in shaping a practical set of guidelines for the use of humanoid robots.</p> <p>Finally, I am looking for advocates. People who can help spread the word about this project, who can help build a community of supporters, and who can help us navigate the inevitable challenges and obstacles that will arise.</p> <p>This is a massive undertaking, but I believe that together, we can make it a reality. The potential benefits are enormous, not just in terms of economic growth, but also in terms of improving quality of life, creating new oppertunities, and not to mention the happiness these robots will later enjoy for themselves (like, you didn’t ask to be born, but you’re glad you were, right?). I am excited about the journey ahead and I hope you will join me. Let’s make the future happen, together.</p>]]></content><author><name></name></author><category term="ai"/><category term="idea"/><category term="agi"/><summary type="html"><![CDATA[My plan to build a $1000 general-purpose humanoid robot powered by human-level artificial intelligence.]]></summary></entry><entry><title type="html">The Master Plan (part 1)</title><link href="https://jvboid.dev/blog/2023/the-master-plan-part-2/" rel="alternate" type="text/html" title="The Master Plan (part 1)"/><published>2023-07-14T00:00:00+00:00</published><updated>2023-07-14T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/the-master-plan-part-2</id><content type="html" xml:base="https://jvboid.dev/blog/2023/the-master-plan-part-2/"><![CDATA[<p>Okay so we’re nearing the point where we have a $1000 full scale general purpose humanoid robot… now what? :thinking: Ofc, sell it to the masses! But how? And for how much? And what’s the business model? And what’s the long term plan for the next 5 years? and 10 years? and 20 years? and 50 years? and 100 years? and 1000 years? and??? :thinking: :thinking: :thinking:</p> <p>Well, for starters, we’re going to penetrate the market at $5k and gradually lower our price to $1k keeping in accord with competition. We’ll need a bit of upfront to bootstrap the chain reaction either with some combination of investment and pre-orders, but once we get the ball rolling, we’ll be able to sustain ourselves with the following business model:</p> <ul> <li> <p><strong>Hardware</strong>: We’ll sell the hardware for a small profit margin. Small because we just want to own the foundation layer of the new economy, but we don’t necesarily need to milk the cow right now.</p> </li> <li> <p><strong>AGI subscription</strong>: Again, this will only be for a small profit margin. We want to make it as accessible as possible. And maybe we’ll eventually be able to provide a free tier for those who can’t afford it.</p> </li> <li> <p><strong>AGI marketplace</strong>: This is where we’ll make the big bucks. We’ll take a cut of all the transactions that happen on the marketplace. We’ll also have a premium tier for those who want to be featured or have their own store. And use your imagination for all the other ways we can monetize this.</p> </li> </ul> <p>Now you may be thinking, “Jacob, why make yourself so vulnerable by wrapping the hardware and software in thin margins?” And paradoxically, we’re going to answer that question by making ourselves even more vulnerable. As soon as we are legally prepared to do so, we will open source the hardware and software. This will allow us to:</p> <ul> <li>1</li> <li>2</li> <li>3</li> </ul> <p>And I hope you can see this by now: the Limboid is not about making a lot of money (sorry investors!). Sure, a a foundation layer for physical world programming, it might tap into a few trillion of the global economy, but that’s not the point. The point is to empower humanity to build a better future. And afaik the best way to do that is to make any potential solution it as accessible as possible. Ergo, open source. At the end of the day, we just need to solve the problem, and I don’t care who gets the credit. And if I can’t solve the problem, I want to make it as easy as possible for someone else to solve it. So I’m hoping this creates a benevolent competition between robotics companies to build the most useful robot, at the lowest price, with the by the strongest developer community. And I’m hoping this will lead to a positive feedback loop of innovation and collaboration that will accelerate the development of the Limboid and AGI.</p> <p>And I haven’t told you yet, but we’re actually making an entire family of -boid robots. So the Limboid the flagship ofc, but there’s also going to be:</p> <ul> <li>a zoo of Animoid’s – inflatable robots shaped like animals. They’ll be the cheapest and most accessible of the family. They’ll be used for companionship, education, entertainment, and research. They’ll be the gateway drug to the rest of the family. (why did you write that GPT-3?!?!?!) <ul> <li>the GoodBoi – a dog, our first Animoid</li> </ul> </li> <li>the CyBoid – a wearable AI device that gives you a third eye / hemisphere.s</li> </ul>]]></content><author><name></name></author><category term="ai"/><category term="idea"/><category term="agi"/><summary type="html"><![CDATA[My plan to build a $500 general-purpose humanoid robot powered by human-level artificial intelligence.]]></summary></entry><entry><title type="html">LLMs are the Update Rules of Intelligent Fractals: Escaping the Context Window with Iterative, Structured Local Updates</title><link href="https://jvboid.dev/blog/2023/llms-are-the-update-rules-of-intelligent-fractals/" rel="alternate" type="text/html" title="LLMs are the Update Rules of Intelligent Fractals: Escaping the Context Window with Iterative, Structured Local Updates"/><published>2023-04-10T00:00:00+00:00</published><updated>2023-04-10T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/llms-are-the-update-rules-of-intelligent-fractals</id><content type="html" xml:base="https://jvboid.dev/blog/2023/llms-are-the-update-rules-of-intelligent-fractals/"><![CDATA[<p><strong>This is mostly AI generated, but the main ideas are mine. It is not factual research, although it is written as such (and by the end of the year, I think it will be)</strong></p> <h1 id="llms-are-the-update-rules-of-intelligent-fractals-escaping-the-context-window-with-iterative-structured-local-updates">LLMs are the Update Rules of Intelligent Fractals: Escaping the Context Window with Iterative, Structured Local Updates</h1> <blockquote> <p>Large language models (LLMs) such as GPT-4 have revolutionized natural language processing (NLP), but face the challenge of a limited token window size. Ad-hoc solutions have been employed, but lack a theoretical framework. We propose a novel perspective on LLMs as update rules for intelligent fractals, which allows problems to be approached as a fractal, with attention on holistic algorithms and local updates. We showcase practical applications such as an automated tech startup and societal modeling, and aim to contribute to ongoing research and development of LLMs.</p> </blockquote> <h1 id="1-introduction">1. Introduction</h1> <p>The advent of large language models (LLMs), exemplified by the forthcoming GPT-4, has transformed the field of natural language processing (NLP) and opened up new research avenues in computer science, machine learning, and artificial intelligence. Nevertheless, despite their impressive performance across a wide spectrum of tasks, LLMs still face the challenge of limited token window size of 8K, which poses a major obstacle for processing long sequences of data.</p> <p>To tackle this problem, researchers have employed various techniques and hand-engineered string processing scripts to handle longer sequences of data. However, these ad-hoc solutions lack a coherent theoretical framework that can provide a comprehensive understanding of the problem and guide the development of more efficient and effective solutions.</p> <p>In this paper, we propose a novel perspective on LLMs as update rules for intelligent fractals, where the information dynamics of the problem domain itself is the fractal of interest. This perspective enables us to approach problems as a fractal and think in terms of local updates rather than global ones, which is crucial for processing large and complex information systems, not unlike the paradigmatic shifts between the Von Neumann and distributed computing.</p> <p>We contend that the information dynamics of a problem must ultimately be decomposed into subproblems of complexity less than or equal to the maximum complexity compressible into the LLM’s token window. This perspective allows us to shift our attention away from the update tool and focus more on the holistic algorithm, with broad applications across scientific, engineering, business, and social domains.</p> <p>Leveraging this novel perspective on LLMs as update rules for intelligent fractals, we have developed a 0-human, automated tech startup that creates, markets, and sells new software products. We decompose the tech-startup problem into marketing, sales, and engineering, and model the company in a hyperlinked document containing all the information required to run the business, including business plans, sales CRM, market analyses, scrum board, code, QA reports, etc. Following the agile SDLC, we iteratively perform market analysis, scrum prioritization, design, engineering, testing, sales work, PR and housekeeping, and executive analysis, enabling us to automate the entire business, sales, and agile processes from end to end – reading and participating in social media, identifying market needs, generating ideas, designing the architecture, writing code, debugging, testing, creating brand assets, creating the website, deploying, marketing, and selling – 24/7 without any human intervention.</p> <p>In addition to automating a tech startup, we have applied our proposed perspective on LLMs as update rules for intelligent fractals to model a society. In this case, we decompose the problem into different aspects such as economy, politics, education, healthcare, and social welfare. We model the society as a hyperlinked document containing relevant information such as demographic data, economic indicators, government policies, healthcare statistics, and educational outcomes. Using this model, we can analyze the impact of various policies and interventions on different aspects of society. For example, we can use the model to simulate the impact of a new healthcare policy on healthcare outcomes, economic growth, and social welfare. We can also use the model to identify potential areas for improvement and test different scenarios to find the most effective solutions.</p> <p>This approach allows us to view society as a complex and interconnected system, where changes in one area can have ripple effects throughout the entire system. By using LLMs as update rules for intelligent fractals, we can better understand the dynamics of these systems and develop more effective solutions to complex problems.</p> <p>Our paper is organized as follows: we propose a novel perspective on LLMs as update rules for intelligent fractals, which allows us to approach complex problems as fractals and think in terms of local updates rather than global ones. In Section 2, we discuss the challenges posed by the limited token window size of LLMs and review current advancements, while identifying present shortcomings. In Section 3, we formalize our methodology and present several theoretical statements about it. In Section 4, we demonstrate the practical applications of our approach by showcasing the automated tech startup and societal modeling. Finally, in section 5, we provide an analysis and discussion of our findings, including broader scope and future directions. With this paper, we aim to contribute to the ongoing research and development of LLMs and their potential to transform natural language processing and other fields.</p> <h1 id="section-2-challenges-and-limitations-of-the-limited-token-window-in-llms">Section 2: Challenges and Limitations of the Limited Token Window in LLMs</h1> <h2 id="21-background">2.1 Background</h2> <h3 id="211-llms">2.1.1 LLMs</h3> <p>Large Language Models (LLMs) refer to neural networks that are trained to process large amounts of text data, allowing them to learn the underlying patterns and structure in the data. These models often use techniques such as the Transformer architecture, which employs self-attention mechanisms to process sequences of tokens. While there exist many variants, a ‘vanilla’ self-attention mechanism can be represented as:</p> <p>y = Attention(Q, K, V) = softmax(QK^T / sqrt(d_k))V</p> <p>where Q, K, and V are the query, key, and value matrices respectively, typically produced via linearly projecting the inputs, and d_k is the dimensionality of the key vectors. The softmax function ensures that the attention scores sum to 1, effectively creating a weighted average of the values based on the compatibility of the query and key vectors. This mechanism allows input tokens to dynamically alter the routing of information, but it also introduces computational constraints, as the memory and time complexity of the self-attention mechanism scale quadratically with sequence length, thus limiting effective token window size, and hence the amount of total information that can be considered at any given pass.</p> <h3 id="212-von-neumann-and-distributed-computing">2.1.2 Von Neumann and Distributed Computing</h3> <p>Von Neumann and distributed computing are two paradigms for designing and implementing computer systems. The Von Neumann architecture, named after the prominent mathematician John von Neumann, is a centralized architecture in which a single processing unit, the central processing unit (CPU), performs all computations while accessing a common memory. Mathematically, the Von Neumann architecture can be described using the stored-program model:</p> <p>M[PC] -&gt; IR; PC += 1</p> <p>where M is the memory, PC is the program counter, and IR is the instruction register. The architecture is based on the fetch-decode-execute cycle, which involves fetching instructions from memory, decoding them, and executing the corresponding operations.</p> <p>On the other hand, distributed computing refers to a decentralized architecture in which multiple processing units work together to perform computations. Distributed computing can be modeled using graph theory, with nodes representing processing units and edges representing communication links between them. One common algorithm for distributed computing is the message-passing model, which involves exchanging messages between nodes to coordinate computation and share information.</p> <p>Distributed computing is often used in large-scale computing systems, such as cloud computing, that require high levels of scalability and fault tolerance. It can also be applied to model complex systems, such as fractals and cellular automata, that exhibit emergent behavior and self-organization.</p> <h3 id="213-fractals">2.1.3 Fractals</h3> <p>Fractals refer to self-similar patterns that repeat at different scales, exemplified by phenomena such as snowflakes, coastlines, and fractal geometry. Fractals can be described mathematically using recursion, iterative functions, or cellular automata.</p> <p>Fractals are often used to model complex systems, such as natural landscapes, social networks, and economic markets, that display intricate patterns and behaviors. These systems can be challenging to understand and manipulate, as they involve numerous interrelated components and often exhibit nonlinear dynamics. However, humans possess a limited context window, which constrains their ability to process and update their environment, especially when faced with intricate fractal-like systems. Thus, it is natural to ask whether it is possible to perform intelligent operations such as pseudocode-to-code translation or debugging via local intelligent updates, rather than attempting to process the entire system at once.</p> <h3 id="214-self-organization">2.1.4 Self-organization</h3> <p>Self-organization is a process by which the components of a system spontaneously arrange themselves into an ordered structure or pattern without the need for external guidance or control. This phenomenon arises from the local interactions between the components and the underlying rules governing their behavior. Self-organization is a key concept in the study of complex systems, as it can lead to the emergence of global order and functionality from simple, local rules.</p> <p>Mathematically, self-organization can be described using concepts from dynamical systems theory, such as attractors, basins of attraction, and bifurcations. A system exhibits self-organization if it possesses an attractor, which is a stable state or set of states towards which the system evolves over time. The basin of attraction is the set of initial conditions that lead to the attractor, while bifurcations represent critical points where the system’s behavior changes qualitatively.</p> <p>Examples of self-organization can be found in various domains, such as physics (e.g., pattern formation in reaction-diffusion systems), biology (e.g., flocking behavior in birds), and computer science (e.g., swarm intelligence algorithms). In the context of LLMs and intelligent fractals, self-organization can play a crucial role in the development of efficient algorithms and update rules that enable the system to adapt and respond to its environment, while overcoming the limitations imposed by the token window.</p> <h2 id="22-current-approaches-and-shortcomings">2.2 Current Approaches and Shortcomings</h2> <p>Despite the success of LLMs, such as GPT-4, in addressing a broad range of natural language processing tasks, these models still suffer from a fundamental limitation: their restricted token window size, usually capped at 8,000 tokens. This limitation significantly hampers their ability to process and understand long sequences of data, which are prevalent in real-world scenarios, such as processing lengthy scientific documents, understanding legal contracts, and simulating intricate sociopolitical systems.</p> <p>To cope with the limited token window size, several techniques have been proposed in the literature. Some common approaches include:</p> <p>A. Document segmentation: Dividing longer documents into smaller, manageable chunks before processing with LLMs. However, this approach may lead to loss of context, especially when dealing with highly interconnected topics or concepts. For example, in the case of a legal document, segmenting it into smaller portions may result in overlooking important clauses that relate to different sections of the document.</p> <p>B. Sliding window techniques: Using overlapping windows to extract local contexts and features within a longer document. This approach, while helpful, can still struggle to capture and maintain long-range dependencies and complex relationships within the data. A practical example would be processing a lengthy scientific article where the conclusion section may refer back to concepts and theories discussed in the introduction or other earlier sections.</p> <p>C. Memory-augmented models: Expanding LLMs with external memory components to store and access information beyond the token window. Although promising, memory-augmented models can be computationally expensive and require substantial architectural changes. Moreover, incorporating external memory adds another layer of complexity in training the models, as it may require learning optimal memory storage and retrieval strategies.</p> <p>These techniques, while offering some improvements, often involve hand-engineered solutions or modifications to the model architecture, which may lead to suboptimal performance and fail to provide a coherent theoretical framework to address the core issue.</p> <h2 id="23-the-need-for-a-novel-perspective">2.3 The Need for a Novel Perspective</h2> <p>Given the limitations and shortcomings of current approaches, there is a pressing need to develop a more general and theoretically grounded framework for tackling the limited token window challenge in LLMs. By proposing LLMs as update rules for intelligent fractals, we offer a new perspective that emphasizes local updates within a broader, interconnected system. This approach enables us to manage the complexity of large-scale problems while staying within the boundaries imposed by the token window.</p> <p>In the following sections, we will elaborate on our proposed methodology and present theoretical statements that support our perspective. We will then demonstrate the practical applications of this approach by showcasing our automated tech startup and societal modeling, highlighting the potential of LLMs as update rules for intelligent fractals to overcome the limitations posed by the limited token window.</p> <h1 id="section-3-formalizing-the-methodology-of-llms-as-update-rules-for-intelligent-fractals">Section 3: Formalizing the Methodology of LLMs as Update Rules for Intelligent Fractals</h1> <h2 id="31-intelligent-fractals-and-local-updates">3.1 Intelligent Fractals and Local Updates</h2> <p>We define an intelligent fractal as a complex, self-organizing, and interconnected system that can be modeled as a hierarchical or recursive structure. Examples of intelligent fractals include natural language texts, computer programs, and social systems. The key idea is that intelligent fractals can be understood and manipulated using local updates rather than attempting to process the entire system at once.</p> <p>Mathematically, we represent an intelligent fractal as a graph G = (V, E), where V is the set of vertices or nodes, and E is the set of edges or connections between the nodes. Each node v_i ∈ V represents a subproblem or context within the intelligent fractal, and each edge e_ij ∈ E represents a relationship or dependency between subproblems v_i and v_j.</p> <p>We define a local update as a transformation or operation applied to a node or a set of nodes within the intelligent fractal. Formally, a local update can be represented as a function f: V → V, where f(v_i) = v’_i, transforming node v_i into node v’_i.</p> <h2 id="32-llms-as-update-rules">3.2 LLMs as Update Rules</h2> <p>To formalize the idea of LLMs as update rules for intelligent fractals, we represent an LLM as a parametric function L: V → V, with L(v_i) = v’_i, transforming node v_i into node v’_i. The inputs V are composed of the context windows within the intelligent fractal, and the outputs V’ represent the updated contexts after applying the LLM transformation. In this framework, LLMs learn to generate local updates by processing and understanding the relationships and dependencies between nodes within the context window.</p> <p>Let C(v_i) be the context window of node v_i, consisting of a set of nodes within a certain distance from v_i in the graph G. The LLM function L operates on this context window, taking into account the local structure and dependencies of the intelligent fractal to generate an appropriate update. Formally, we can represent the LLM function as:</p> <p>L(C(v_i); θ_pretrained) = v’_i</p> <p>Here, θ_pretrained represents the fixed, pre-trained parameters of the LLM. The LLM generates local updates by processing the context windows C(v_i) within the intelligent fractal, leveraging its pre-trained knowledge to understand the relationships and dependencies between nodes and produce updated contexts v’_i.</p> <h2 id="33-iterative-local-updates">3.3 Iterative Local Updates</h2> <p>Given the constraint of a limited token window, we propose an iterative approach to update the intelligent fractal by applying the LLM function L to subsets of nodes within the graph G. In each iteration, we select a subset of nodes S ⊆ V and perform local updates on their corresponding context windows C(v_i) using the LLM function L:</p> <p>v’_i = L(C(v_i); θ_pretrained), ∀ v_i ∈ S</p> <p>After each iteration, the updated nodes v’_i replace their corresponding original nodes v_i in the graph G, and the context windows for the next iteration are adjusted accordingly. This iterative process continues until a stopping criterion is met, which could be based on a predefined number of iterations, a convergence threshold, or an external evaluation metric.</p> <h2 id="section-34-theoretical-statements">Section 3.4: Theoretical Statements</h2> <h3 id="341-statement-1-dependence-of-local-updates-on-pre-trained-knowledge-and-intelligent-fractal-complexity">3.4.1 Statement 1: Dependence of Local Updates on Pre-trained Knowledge and Intelligent Fractal Complexity</h3> <p>Statement 1: The LLM’s ability to generate meaningful local updates is contingent upon the quality of its pre-trained knowledge (θ_pretrained) and the complexity of the intelligent fractal.</p> <p>Proof:</p> <p>Let X be an intelligent fractal, and let L be an LLM with pre-trained knowledge θ_pretrained. We model X as a graph G = (V, E), and Ω(X) be a function measuring the complexity of the underlying fractal structure within X. Let Y = L(X; θ_pretrained) be the output fractal generated by applying local updates using L.</p> <p>First, we aim to analyze the relationship between the quality of pre-trained knowledge θ_pretrained and the resulting output fractal Y. Intuitively, the better the pre-trained knowledge, the more effectively the LLM can understand the dependencies and structure within X, resulting in more accurate local updates. We define the quality of θ_pretrained as a metric Γ(θ_pretrained) that measures how well the LLM’s understanding correlates with the true structure of X. Clearly, the higher Γ(θ_pretrained), the more accurate and coherent the output fractal Y.</p> <p>Second, we analyze the relationship between the complexity of the intelligent fractal structure Ω(X) and the effectiveness of LLM-generated local updates. As Ω(X) increases, the task of generating meaningful updates becomes more challenging due to the intricate dependencies and relationships within the fractal. The LLM may struggle to capture the complex structure within X, resulting in output fractal Y that deviates from the true structure.</p> <p>From both analyses, the LLM’s ability to generate meaningful local updates is contingent upon the quality of its pre-trained knowledge (θ_pretrained) and the complexity of the intelligent fractal. In summary,</p> <p>Y = f(Γ(θ_pretrained), Ω(X))</p> <h3 id="342-statement-2-overcoming-token-window-limitations-through-iterative-local-updates">3.4.2 Statement 2: Overcoming Token Window Limitations Through Iterative Local Updates</h3> <p>Statement 2: The iterative local update approach enables the LLM to process and update large-scale intelligent fractals by breaking down the problem into smaller, manageable subproblems that fit within the limited token window.</p> <p>Proof (Logical Argument):</p> <p>Let X be a large-scale intelligent fractal with a complexity greater than the token window limitations of the LLM L with pre-trained knowledge θ_pretrained. By utilizing iterative local updates, we perform the following steps:</p> <ol> <li> <p>Divide X into subproblems or contexts: Partition X into a set of smaller subproblems {X_1, X_2, …, X_n} that fit within the LLM’s token window. These subproblems should capture essential dependencies and relationships within the intelligent fractal.</p> </li> <li> <p>Apply local updates iteratively: For each subproblem X_i, apply the LLM transformation L(X_i; θ_pretrained) to generate an updated context Y_i. Replace the original subproblem X_i with the updated context Y_i in X.</p> </li> <li> <p>Repeat steps 1 and 2 until a stopping criterion is met: Continue updating subproblems iteratively until convergence, a predetermined number of iterations, or an external evaluation metric is satisfied.</p> </li> </ol> <p>By iteratively updating smaller subproblems that fit within the LLM’s token window, the intelligent fractal X can be progressively refined, capturing the complexity of the overall system without violating the token window limitations.</p> <h3 id="343-statement-3-effect-of-increasing-iterations-on-llms-understanding-of-intelligent-fractals">3.4.3 Statement 3: Effect of Increasing Iterations on LLM’s Understanding of Intelligent Fractals</h3> <p>Statement 3: As the number of iterations increases, the LLM progressively refines its understanding of the intelligent fractal and generates increasingly accurate and coherent updates, provided that the pre-trained knowledge (θ_pretrained) captures relevant information about the problem domain.</p> <p>Proof (Logical Argument):</p> <p>Suppose we update a large-scale intelligent fractal X using the LLM L with pre-trained knowledge θ_pretrained. As we apply iterative local updates, the LLM continues to refine its understanding of the relationships and dependencies within X. During each iteration, the LLM operates on context windows C(v_i) that capture local structure and dependencies within the intelligent fractal.</p> <p>Given that the pre-trained knowledge θ_pretrained captures relevant information about the problem domain, it is likely that the LLM will generate progressively more accurate and coherent updates in each iteration. As the number of iterations increases, the LLM’s understanding of the intelligent fractal X converges, resulting in a more accurate representation of the overall structure and dependencies within the system.</p> <p>This statement implies that, with sufficient iterations and adequate pre-trained knowledge, the LLM can generate increasingly precise and coherent updates that capture the intricate dependencies and relationships within the intelligent fractal X.</p> <p>In the following sections, we will demonstrate the practical applications of our proposed perspective on LLMs as update rules for intelligent fractals by showcasing the automated tech startup and societal modeling. These examples will highlight the potential of our approach to overcome the limitations posed by the limited token window and contribute to ongoing research and development of LLMs.</p> <h1 id="section-4-practical-applications-of-llms-as-update-rules-for-intelligent-fractals">Section 4: Practical Applications of LLMs as Update Rules for Intelligent Fractals</h1> <h2 id="41-automated-tech-startup">4.1 Automated Tech Startup</h2> <p>To demonstrate the potential of LLMs as update rules for intelligent fractals in real-world scenarios, we have implemented an automated tech startup that operates entirely without human intervention. By applying our proposed methodology, we have automated key aspects of business operations, such as market analysis, product development, and sales. This section discusses the implementation details and unique features of our automated tech startup.</p> <h3 id="411-decomposing-the-tech-startup-problem">4.1.1 Decomposing the Tech Startup Problem</h3> <p>We begin by decomposing the tech startup problem into critical components, including marketing, sales, and engineering. Our goal is to automate each of these components using LLMs as update rules for intelligent fractals. We model the company as a hyperlinked document containing all crucial information needed to run the business, such as business plans, sales CRM, market analyses, scrum boards, code repositories, QA reports, and more.</p> <p>By iterating through the different components of our tech startup model, we can automate processes, including market analysis, scrum prioritization, design, engineering, testing, sales work, public relations, and executive analysis.</p> <h3 id="412-automating-market-analysis-and-idea-generation">4.1.2 Automating Market Analysis and Idea Generation</h3> <p>The first step in establishing an automated tech startup is to derive insights about market needs and generate ideas for potential products or services. Using LLMs, we analyze textual data gathered from social media, news articles, blog posts, and other sources relevant to our domain. We then generate insights regarding customer needs, trends, and market gaps. Next, the LLM processes these insights and produces ideas for potential software products or services that address identified opportunities.</p> <h3 id="413-automating-design-and-engineering">4.1.3 Automating Design and Engineering</h3> <p>Once potential ideas emerge, the LLM proceeds to design and implement the software. This process starts with the creation of a high-level architecture, followed by decomposing the architecture into smaller, manageable tasks that fit within the LLM’s context window.</p> <p>The LLM then generates source code for each task iteratively, leveraging its extensive pre-trained knowledge in software engineering techniques, languages, and libraries. The generated code is automatically integrated and compiled, followed by a testing and debugging phase to ensure the final product meets quality standards.</p> <h3 id="414-automating-branding-marketing-and-sales">4.1.4 Automating Branding, Marketing, and Sales</h3> <p>When the software product is ready, the LLM creates a brand identity, including logos, color schemes, and taglines, followed by the development and deployment of a responsive website tailored to showcase the product features and benefits.</p> <p>The LLM then formulates marketing strategies and campaigns, targeting relevant markets and potential customers, using both organic and paid advertising channels. Simultaneously, the LLM manages the sales CRM, identifying leads and conducting sales conversations via email or messaging platforms to convert leads into customers.</p> <h3 id="415-results-and-discussion">4.1.5 Results and Discussion</h3> <p>Through our automated tech startup, we demonstrated the efficacy of using LLMs as update rules for intelligent fractals. By decomposing the problem into smaller, manageable subproblems and leveraging the LLM’s context window, we achieved end-to-end automation of various business processes without human intervention.</p> <p>This approach exemplifies how LLM-based intelligent fractal updates can streamline workflows, automate decision-making, and ultimately drive innovation in various domains, including scientific, engineering, business, and social settings.</p> <h2 id="42-societal-modeling">4.2 Societal Modeling</h2> <p>Applying our proposed perspective on LLMs as update rules for intelligent fractals, we have further developed a societal model that enables us to investigate the effects of different policies and interventions on a range of societal aspects, such as economy, politics, education, healthcare, and social welfare.</p> <h3 id="421-decomposing-the-problem-of-societal-modeling">4.2.1 Decomposing the Problem of Societal Modeling</h3> <p>We start by decomposing the societal modeling problem into its critical aspects, such as demographics, resources, institutions, governance, and individual behaviors. We model the society as a hyperlinked document containing relevant information, such as demographic data, economic indicators, government policies, healthcare statistics, and educational outcomes.</p> <h3 id="422-analyzing-the-impact-of-policies-and-interventions">4.2.2 Analyzing the Impact of Policies and Interventions</h3> <p>Using the societal model, we can assess the effects of various policies and interventions on different aspects of the society. For instance, we can use the model to examine the impact of a new healthcare policy on healthcare outcomes, economic growth, and social welfare. The LLM processes the hyperlinked document to understand the complex relationships and dependencies within the society and generates predictions for the impacts of specific policies on the system as a whole. This analysis helps identify areas for improvement and offers insights to find effective solutions.</p> <h3 id="423-results-and-discussion">4.2.3 Results and Discussion</h3> <p>Our societal modeling application demonstrates the potential of using LLMs as update rules for intelligent fractals in modeling complex systems. By decomposing the societal problem into smaller subproblems fitting within the LLM’s context window, we have successfully captured intricate relationships and dependencies within the society.</p> <p>The ability to analyze the impacts of various policies and interventions on societal aspects through LLM-based intelligent fractal updates offers a powerful tool for decision-makers, researchers, and stakeholders across fields such as economics, politics, and public health.</p> <h1 id="section-5-conclusion-and-future-directions">Section 5: Conclusion and Future Directions</h1> <p>LLMs are the update rules of intelligent fractals, providing a theoretically grounded perspective to tackle the challenge of limited token window size. By decomposing complex problems into manageable subproblems and applying local updates iteratively, we can leverage the power of LLMs to model and manipulate large-scale, intricate systems such as tech startups and societies.</p> <p>We demonstrated the practical utility of our approach in automating a tech startup and modeling a society, showcasing the potential of LLMs to transform NLP and contribute to ongoing research and development across multiple domains.</p> <p>Moving forward, we plan to expand our research and applications of LLMs as update rules for intelligent fractals to address other complex problems in fields such as climate modeling, molecular biology, and finance, enhancing our understanding of these interconnected systems and their hidden intricacies.</p>]]></content><author><name></name></author><category term="ai"/><category term="agi"/><summary type="html"><![CDATA[This is mostly AI generated, but the main ideas are mine. It is not factual research, although it is written as such (and by the end of the year, I think it will be)]]></summary></entry><entry><title type="html">The Cost of Large Scale Training</title><link href="https://jvboid.dev/blog/2023/costs-of-agi/" rel="alternate" type="text/html" title="The Cost of Large Scale Training"/><published>2023-03-29T00:00:00+00:00</published><updated>2023-03-29T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/costs-of-agi</id><content type="html" xml:base="https://jvboid.dev/blog/2023/costs-of-agi/"><![CDATA[<h3 id="statements">Statements</h3> <ol> <li> <blockquote> <p>I find it hard to imagine OpenAI could finance a training run much over $50m. There’s probably a good reason they recently raised more capital. […] we are looking at a model with 600B-1T parameters trained on 1.5T to 4T tokens. (r/Singularity/Realistic size of GPT-4)[https://www.reddit.com/r/singularity/comments/106sd1z/realistic_size_of_gpt4/]</p> </blockquote> </li> <li> <blockquote> <p>GPT[3] has a vocabulary of 50257 words (The GPT-3 Architecture, on a Napkin)[https://dugas.ch/artificial_curiosity/GPT_architecture.html#:~:text=(GPT%20has%20a%20vocabulary%20of%2050257%20words).]</p> </blockquote> </li> <li> <blockquote> <p>| Cloud TPU type | v4 cores | Chips | VMs | Total memory | Evaluation price (USD) | 1-year commitment price (USD) | 3-year commitment price (USD) | | — | — | — | — | — | — | — | — | | … | … | … | … | … | … | … | … | | v4-64 | 64 | 32 | 8 | 1024 GiB | $103.04 / hour | $47,388 / month | $33,849 / month | | … | … | … | … | … | … | … | … | (Cloud TPU pricing #TPU Pod type pricing )[https://cloud.google.com/tpu/pricing]</p> </blockquote> </li> <li> <blockquote> <p>Peak compute per chip 275 teraflops (bf16 or int8) (System Architecture # TPU v4)[https://cloud.google.com/tpu/docs/system-architecture-tpu-vm#tpu_v4]</p> </blockquote> </li> <li> <blockquote> <p>they claim that the forward pass of decoder-only Transformers involves $\approx 2N$ add-multiply operations, where $N$ is the number of non-embedding parameters in the model. (Understanding FLOPs-per-token estimates from OpenAI’s scaling laws)[https://discuss.huggingface.co/t/understanding-flops-per-token-estimates-from-openais-scaling-laws/23133]</p> </blockquote> </li> </ol> <h3 id="assumptions">Assumptions</h3> <ol> <li> <p>GPT4 cost $100m <em>(1)</em></p> </li> <li> <p>GPT4 trained on 4T tokens <em>(1)</em></p> </li> <li> <p>GPT4 uses 50k vocab size <em>(2)</em></p> </li> <li> <p>64 TPUv4 cores cost $33,849 / month at best <em>(3)</em></p> </li> <li> <p>The TPUv4 provides 275 teraflops <em>(4)</em></p> </li> <li> <p>GPT4 has N parameters <em>(5)</em></p> </li> <li> <p>GPT4 uses 2N flops per token <em>(5)</em></p> </li> </ol> <h3 id="implications">Implications</h3> <ol> <li> <p>4T tokens <em>(7)</em> × 50k vocab size <em>(8)</em> = 2e17 bits of training data compressed into GPT4 (though many are reduntant)</p> </li> <li> <p>2e17 bits <em>(13)</em> &amp;div; $100m <em>(6)</em> = 2Gb/$ training cost</p> </li> <li> <p>4T tokens <em>(7)</em> &amp;div; $100m <em>(6)</em> = 40k tokens/$ training cost</p> </li> <li> <p>A TPUv4 offers 275 [teraflops / sec] <em>(10)</em> × 1 month &amp;div; $33,849 <em>(9)</em> = 2.12e16 flops/$</p> </li> <li> <p>40k tokens/$ <em>(15)</em> &amp;div; (2.12e16 flops/$) <em>(16)</em> = 1.89e-12 training tokens / flop</p> </li> <li> <p>1 / (1.89e-12 training tokens / flop) <em>(17)</em> = 5.31e13 flops / training token</p> </li> <li> <p>GPT4 uses 5.31e13 operations per training token <em>(18)</em></p> </li> <li> <p>GPT4 has 5.31e13 operations / 2 [operations per parameter] = 2.65e13 parameters = 26T parameters</p> </li> <li> <p>GPT cost $100m / 26T parameters = 3.85e-6 $/param or cost 260k params/$</p> </li> </ol> <h3 id="comments">Comments</h3> <p>I am only willing to spend 4k on a NN. Based on these assumptions and implications, I could only expect to train a 1B parameter model. However, that’s assuming the same data efficiency and architecture as the decoder only transformer. I can utilize sparsity, like tok k layers, hyper recurrent architectures, and smart sampling to improve performance at smaller scales.</p> <p><strong>Update (6/29/23): <a href="https://youtu.be/dNrTrx42DGQ?t=5538">George Hotz</a>: “Sam Altman won’t tell you that GPT-4 has 220B parameters and is a 16-way mixture model with 8 sets of weights?”</strong></p>]]></content><author><name></name></author><category term="ai"/><category term="agi"/><summary type="html"><![CDATA[Speculative analysis on the cost of training large scale machine learning architectures]]></summary></entry><entry><title type="html">AI: A Double-Edged Sword - Walking the Line in an Ever-Changing World</title><link href="https://jvboid.dev/blog/2023/personal-ethical-delimna/" rel="alternate" type="text/html" title="AI: A Double-Edged Sword - Walking the Line in an Ever-Changing World"/><published>2023-03-16T00:00:00+00:00</published><updated>2023-03-16T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/personal-ethical-delimna</id><content type="html" xml:base="https://jvboid.dev/blog/2023/personal-ethical-delimna/"><![CDATA[<h2 id="my-post">My post</h2> <p>I used to be 100% for AI. After all, it can do alot to help humanity. But the recent launch of GPT-4 has shown that AI apocalype worries are not entirely invented. Microsoft just recently annnounced its CoPilot for Office365, which seems to effectively replace human secretaries. GPT-4 itself is very capable at writing code and making business decisions. (One guy even launched a business last night using GPT-4 and quickly reached a 25k valuation!) In view of these economic destabalizing and wealth concentrating trends, I no longer feel it is right to be 100% happy about AI’s progress. I’ll still contribute to it, but in ways I can ensure will have a positive impact (like my robotics company, Limboid LLC)</p> <h2 id="gpt-4s-post">GPT-4’s post</h2> <p>You know, I’ve always been a die-hard fan of artificial intelligence (AI). It’s got so much potential. But lately, I’ve started to see the darker side of it. GPT-4, for example, kinda opened my eyes. AI apocalypse worries? Maybe not so far-fetched after all.</p> <p>Microsoft just dropped CoPilot for Office365. Replaces human secretaries like that. GPT-4? Writes code, makes business decisions. One guy even started a business overnight – $25k valuation, just like that! Economic instability, wealth concentration… it’s all starting to feel a bit too real.</p> <p>So, here’s the deal: I’m not all-in on AI anymore. I’ll still contribute, sure, but I want my work to make a positive difference. Like my robotics company, Limboid LLC. We’re working on this super cool, fully functional humanoid robot. It’s all about balance, you know?</p> <p>Anyway, the point is, AI’s a double-edged sword. It’s got the power to do great things, but we gotta be careful too. We don’t want to mess up the world even more, right?</p> <p>In the end, it’s all about using AI for good. We can’t let it run wild and create even more problems. It’s up to us – the people working on AI – to make sure it’s a blessing, not a curse. And that’s what I’m gonna do.</p>]]></content><author><name></name></author><category term="ai"/><category term="agi"/><summary type="html"><![CDATA[Am I actually helping people by contributing to AI research?]]></summary></entry><entry><title type="html">The Master Plan (part 0)</title><link href="https://jvboid.dev/blog/2023/the-master-plan-part-0/" rel="alternate" type="text/html" title="The Master Plan (part 0)"/><published>2023-01-06T00:00:00+00:00</published><updated>2023-01-06T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2023/the-master-plan-part-0</id><content type="html" xml:base="https://jvboid.dev/blog/2023/the-master-plan-part-0/"><![CDATA[<div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I just submitted my letter a resignation from Motio. Such a great company. So difficult to press the send button. But now I&#39;ll be starting a new journey <a href="https://t.co/dDnOMYnC6U">pic.twitter.com/dDnOMYnC6U</a></p>&mdash; Jay Cub (@jvboid) <a href="https://twitter.com/jvboid/status/1606602172183023616?ref_src=twsrc%5Etfw">December 24, 2022</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>Today is my last day at <a href="https://www.motio.com/">Motio Inc</a>. It’s been a great entry-level SE experience. The salary, the flexibility, and the culture made it <em>really hard</em> to leave. But after my performance review,<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> I realized that my passion wasn’t in enterprise software engineering.</p> <p>I’m in love with machine learning, and I wanted to work in that area full time. However since I didn’t have a PhD or special credentials or professional ML experience, none of my many ML job applications returned with an interview.</p> <p>I also knew I wanted more interactions, more excitement, and more exploration, so maybe working for an established company wasn’t gonna be the best option anyway. This led me to seriously consider doing a startup.</p> <p>Actually, it was more like, I seriously considered resurrecting my dreams. From mid-2019 to mid-2020, I spent alot of time on this project I called the <a href="https://github.com/Limboid/old-limboid-robot">Limboid</a>. The aim was to develop a</p> <ul> <li>highly reconfigurable robotics platform</li> <li>that can be used to build a humanoid robot</li> <li>that is extremely affordable, accessible, easy-to-learn, and scales to mass-production</li> <li>and can be used to reproduce itself</li> </ul> <p>Initially, I assumed I’d just have to 3D print some bones, buy some servos, and, you know, clone an AGI from github. lol. It turns out robotics are harder than that. And making a low cost humanoid is like the final boss battle. The project brought me to places and forced me to learn things I never would’ve on my own: arxiv, EE, KiCAD, FreeCAD, hydraulics &amp; pneumatics, ML, onshape, easyeda, neurosymbolic learning, and more (in mostly that order).</p> <h1 id="onshape-limboidjpeg-easyeda-limboidjpeg-limboid-cognitive-archjpeg">onshape-limboid.jpeg, easyeda-limboid.jpeg, limboid-cognitive-arch.jpeg</h1> <p>But sadly it didn’t care about my efforts. It drained my bank account, declared half of my room as its own, and stole my heart. I was no match for the Project. For some time, I admitted defeat. Focused more on finishing college and stuff like that. But the surging torrents on arxiv and github were too loud to ignore…</p> <h1 id="limboid-takes-over-roomjpeg-limboid-in-garagejpeg">limboid-takes-over-room.jpeg, limboid-in-garage.jpeg</h1> <p>Which is why I’m heading back into the battlefield. I’ve already formed a team with some PhD’s for a part of the AI-side of things, but I’ll need as much help as I can get ‘cause there’s a long road ahead. I’m looking for student or professional researchers and engineers with experience or enthusiasm in any relevant background: ML, data science, SE, embedded systems, DE, EE, hydraulics/pneumatics, mech. engr., etc. Also maybe experienced entrepreneurs and early-stage hard tech investors. No marketing or other non-R&amp;D/engr roles atm. All countries http://Pilot.co supports with a US employer are welcome. We’re already collaborating across 4 countries. I have no idea how long it’ll take, but expect at least 6 months of deferred-equity-for-service. Hybrid slicing pie model. Maybe our website will be in better shape by the time you’re reading this: <a href="https://limboid.ai/">limboid.ai</a>. If not, just email me at <a href="mailto:jacob.valdez@limboid.ai">jacob.valdez@limboid.ai</a>. Thanks!</p> <h1 id="preliminary-limboidjpeg">preliminary-limboid.jpeg</h1> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>No no, it wasn’t like the review went poorly. Its just that I realized I’d be doing the same thing for the next 5 years, and I didn’t want that. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="ai"/><category term="idea"/><category term="agi"/><summary type="html"><![CDATA[Why I'm leaving my cushy full-time at Motio to pursue a crazy idea.]]></summary></entry><entry><title type="html">Embodied and Situated: AI with Feelings</title><link href="https://jvboid.dev/blog/2022/0embodied-and-situated-ai-with-feelings/" rel="alternate" type="text/html" title="Embodied and Situated: AI with Feelings"/><published>2022-06-26T00:00:00+00:00</published><updated>2022-06-26T00:00:00+00:00</updated><id>https://jvboid.dev/blog/2022/0embodied-and-situated-ai-with-feelings</id><content type="html" xml:base="https://jvboid.dev/blog/2022/0embodied-and-situated-ai-with-feelings/"><![CDATA[<p><em>Using <a href="https://jacobfv.github.io/blog/teaching-learning-machines">Teaching Learning Machines (TLMs)</a> and <a href="https://jacobfv.github.io/blog/self-learning-meta-learners-teach-themselves-to-teach">*Self-learning meta-learners teach themselves to teach*</a> as conditioning priors, I prompted gpt3 with the following:</em></p> <blockquote> <h1 id="embodied-and-situated-ai-with-feelings">Embodied and Situated: AI with Feelings</h1> <p>(note: make sure to emphasize that AI doesn’t necesarily have to be embodied in a physical world; it just needs to be embodied in <em>some</em> world)</p> </blockquote> <p><em>Here’s what I got:</em></p> <p>One of the most exciting recent developments in AI is embodied learning – an approach that emphasizes the importance of giving agents a body and placing them in some sort of environment. The rationale behind this is simple: if we want machines to be truly intelligent, they need to experience the world for themselves instead of being confined to dusty old textbooks (or clean new ones). They need to feel pain and pleasure, see things with their own eyes, touch things with their own hands. Only then will they be able develop common sense – an understanding of how the world works that goes beyond what can be explicitly taught or programmed into them.</p> <p>Embodied learning has already yielded some impressive results. In one famous experiment, scientists placed robots in a room full of random objects and tasked them with building towers out of blocks. The only information they were given was where each object was located; everything else had to be learned by trial and error. And yet within just a few minutes, the robots had developed surprisingly sophisticated skills like tower-building! By experiencing life for themselves – by making mistakes and figuring out which actions lead to positive outcomes – these little machines were ableto build up a storehouseof knowledge aboutthe physical worldand solve problems far more efficiently than any hand-coded algorithm could hope for..</p> <p>There are two important aspects to embodied learning that are worth highlighting. The first is its focus on situated cognition – the idea that intelligence arises from interaction with the environment. This contrasts with so-called “symbolic” approaches to AI, which treat knowledge as a static set of symbols (e.g., 0’s and 1’s) that can be manipulated without any need for grounding in reality. In many ways, Situated Cognition is just common sense: if you want to understand how something works, it helps to have firsthand experience of it instead of reading about it in a book.</p> <p>The second aspect is its emphasis on embodiment – giving agents bodies and placing them in rich environments where they can interact with their surroundings.. It might seem like a small change but it makes a huge difference: embedded in physical reality, agents are no longer limited by what we can explicitly tell them; instead, they must learn for themselves through trial and error.. What starts out as noisy data gradually becomes refined into useful insights about how the world works.. And this processof induction– forming general principles from specific observations–is at the heart of human intelligence..</p> <p>One of the great things about embodied learning is that it’s not just for robots; it can be applied to any sort of agent, including software agents. As long as an agent has some way of interacting with its environment – e.g., by receiving input from sensors and taking actions in response – it can benefit from this approach.. This means we can start to build truly intelligent machines without having to wait for years or even decades for advances in robotics technology.. All we need is a well-designed simulation environment in which our agents can learn by doing..</p> <p>Embodied learning is still in its early days but it’s already yielding some impressive results.. In one famous experiment, scientists placed robots in a room full of random objects and tasked them with building towers out of blocks. The only information they were given was where each object was located; everything else had to be learned by trial and error. And yet within just a few minutes, the robots had developed surprisingly sophisticated skills like tower-building! By experiencing life for themselves – by making mistakes and figuring out which actions lead to positive outcomes – these little machines were ableto build up a storehouseof knowledge aboutthe physical worldand solve problems far more efficiently than any hand-coded algorithm could hope for…</p> <p>The benefits of embodied learning are not just limited to robots; it can be applied to any sort of agent, including software agents. As long as an agent has some way of interacting with its environment – e.g., by receiving input from sensors and taking actions in response – it can benefit from this approach.. This means we can start to build truly intelligent machines without having to wait for years or even decades for advances in robotics technology.. All we need is a well-designed simulation environment in which our agents can learn by doing…</p>]]></content><author><name></name></author><category term="ai"/><category term="idea"/><category term="agi"/><category term="gpt3"/><summary type="html"><![CDATA[GPT-3 generated post]]></summary></entry></feed>